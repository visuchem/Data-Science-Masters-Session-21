{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the linear regression model using scikit learn in boston data to predict 'Price' based on other dependent variable.\n",
    "# Here is the code to load the data\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import scipy.stats as stats\n",
    "# import matplotlib.pyplot as plt\n",
    "# import sklearn\n",
    "# from sklearn.datasets import load_boston\n",
    "# boston = load_boston()\n",
    "# bos = pd.DataFrame(boston.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries to load (for data manipulation and analysis)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# Core Libraries to load - Machine Learning\n",
    "import sklearn\n",
    "\n",
    "## Import LinearRegression Module\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "## Import train_test_split Module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Import boston dataset from sklearn.datasets\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "\n",
    "# Import stats module from scipy for Statistical analysis\n",
    "import scipy.stats as stats\n",
    " \n",
    "# Load Boston dataset and create a dataframe    \n",
    "boston = load_boston()\n",
    "bos = pd.DataFrame(boston.data)\n",
    "\n",
    "#Importing mean_squared_error and r2_score from sklearn.metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Understand the dataset and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Get Information about the dataset and the data___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about the dataset\n",
    "print(boston) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get keys of boston dataset dictionary\n",
    "print(boston.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of rows and columns in the dataset\n",
    "boston.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column names in the dataset\n",
    "print(boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get description of the column names in the dataset\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Information of the dataframe created from the data set___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information of the column and top 10 elements of the dataframe \n",
    "bos.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the dataframe\n",
    "bos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Updating the dataframe to make it easy to understand the data___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column headings(0-12) need to be replaced with the column names from the dataset for ease of understanding the dataframe\n",
    "bos.columns = boston.feature_names\n",
    "bos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The dataframe is missing the target or dependent column.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Information about the target from boston dictionary___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the target or dependent column\n",
    "print(boston.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the dataframe by adding the target column  \n",
    "bos[\"PRICE\"] = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Details about Data for Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe shape after updating \n",
    "print(bos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe after updating \n",
    "bos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Check for datatypes and presence of null values using info()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_No cleaning required as the data is already cleaned and has no null or NaN values_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Statistical Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Basic Statistics of Numerical Values___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# All the columns are NUMERICAL. There is no categorical data to consider\n",
    "\n",
    "##Therefore we don't need to use the parameter include=all in describe()\n",
    "print(bos.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Correlation --- WE can move this to exploratory analysis part\n",
    "bos_corr = bos.corr()\n",
    "bos_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Analysis OR Exploratory Analysis of the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the frequency distribution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the histogram of the data to understand the frequency distribution of the data\n",
    "bos.hist(bins=50,figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the relation between different columns in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(bos.iloc[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the correlation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_corr # Correlation between different columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Note about Correlation values:___\n",
    "\n",
    "_If absolute value of correlation co-efficient between 2 variables is >= 0.5,then they are strongly associated with each other._\n",
    "_This implies, they are likely to have a stronger effect on the nature of generated model_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__RM has High positive correlation with PRICE.__\n",
    "__PTRATIO and LSTAT have High negative CORRELATION with PRICE__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for correlations using HEATMAP\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(bos_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bos.drop('PRICE', axis = 1)\n",
    "Y = bos['PRICE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We will be using 80:20 split for train and test datasets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2,  random_state =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Baseline Model (No splits)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.fit(X, Y) # Sklearn already considers the intercepts for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Estimated Beta Coefficients: \\n\", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = X.columns\n",
    "coeff = pd.Series(model.coef_, predictors).sort_values()\n",
    "coeff.plot(kind='bar',title='Feature Co-efficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos.PRICE.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Data points')\n",
    "plt.ylabel('Housing Price')\n",
    "plt.title('Housing price distribution')\n",
    "plt.scatter(range(len(Y)),Y, c= \"green\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Data points')\n",
    "plt.ylabel('Housing Price')\n",
    "plt.title('Housing price distribution')\n",
    "plt.scatter(range(len(pred_Y)),pred_Y, c= \"blue\", label = \"Predicted Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = math.sqrt(mean_squared_error(Y,pred_Y))\n",
    "r_squared =  r2_score(Y,pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The RMSE of model for data with all features is: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The r2_score of model for data with all features is: \", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_metrics = [(\"RMSE\",rmse),  (\"r2_score\",r_squared)]\n",
    "baseline_model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Model from train test split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.fit(train_x.values, train_y.values) # Sklearn already considers the intercepts for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = X.columns\n",
    "coeff = pd.Series(model.coef_, predictors).sort_values()\n",
    "coeff.plot(kind='bar',title='Feature Co-efficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_y = model.predict(train_x)\n",
    "test_pred_y = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = math.sqrt(mean_squared_error(train_y,train_pred_y))\n",
    "rmse_test =  math.sqrt(mean_squared_error(test_y,test_pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The RMSE of model for training data with all features is: \", rmse_train )\n",
    "print(\"The RMSE of model for test data with all features is: \", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_train = r2_score(train_y,train_pred_y)\n",
    "r_squared_test = r2_score(test_y,test_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The r2_score of model for training data with all features is: \", r_squared_train)\n",
    "print(\"The r2_score of model for test data with all features is: \", r_squared_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_model_train_metrics = [(\"RMSE Train\",rmse_train),  (\"r2_score Train\",r_squared_train)]\n",
    "split_model_test_metrics = [(\"RMSE Test\",rmse_test),  (\"r2_score Test\",r_squared_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split_model_train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_model_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos.PRICE.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Training - Actual Vs Predicted')\n",
    "plt.scatter(train_y, train_pred_y, c= \"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Test - Actual Vs Predicted')\n",
    "plt.scatter(test_y, test_pred_y, c= \"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Price')\n",
    "plt.ylabel('Predicted Price Residuals')\n",
    "plt.title('Training - Residuals Plot')\n",
    "plt.scatter(train_y,train_y - train_pred_y, c= \"green\")\n",
    "plt.hlines(y=0,xmin=0,xmax=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Price')\n",
    "plt.ylabel('Predicted Price Residuals')\n",
    "plt.title('Test - Residuals Plot')\n",
    "plt.scatter(test_y, test_y - test_pred_y, c= \"blue\")\n",
    "plt.hlines(y=0,xmin=0,xmax=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Model Performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance by using Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rndf = RandomForestRegressor(n_estimators=150)\n",
    "rndf.fit(train_x, train_y)\n",
    "importance = pd.DataFrame.from_dict({'cols':train_x.columns, 'importance': rndf.feature_importances_})\n",
    "importance = importance.sort_values(by='importance', ascending=False)\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.barplot(importance.cols, importance.importance)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing  Features with  feature importance close to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above, we remove 'CHAS','RAD','INDUS','ZN' to check if it improves the model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X.drop(['CHAS','RAD','INDUS','ZN'], axis=1)\n",
    "Y = bos['PRICE'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We will be using 80:20 split for train and test datasets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x1,test_x1, train_y1, test_y1 = train_test_split(X1, Y, test_size=0.2,  random_state =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x1.shape)\n",
    "print(test_x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_y1.shape)\n",
    "print(test_y1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Model from train test split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.fit(train_x1.values, train_y1.values) # Sklearn already considers the intercepts for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = X1.columns\n",
    "coeff = pd.Series(model.coef_, predictors).sort_values()\n",
    "coeff.plot(kind='bar',title='Feature Co-efficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_y1 = model.predict(train_x1)\n",
    "test_pred_y1 = model.predict(test_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train1 = math.sqrt(mean_squared_error(train_y1,train_pred_y1))\n",
    "rmse_test1 =  math.sqrt(mean_squared_error(test_y1,test_pred_y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The RMSE of model for training data with some features removed is: \", rmse_train1 )\n",
    "print(\"The RMSE of model for test data with some features removed is: \", rmse_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_train1 = r2_score(train_y1,train_pred_y1)\n",
    "r_squared_test1 = r2_score(test_y1,test_pred_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The r2_score of model for training data with all features is: \", r_squared_train1)\n",
    "print(\"The r2_score of model for test data with all features is: \", r_squared_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_split_model_train_metrics = [(\"RMSE Train\",rmse_train1),  (\"r2_score Train\",r_squared_train1)]\n",
    "removed_split_model_test_metrics = [(\"RMSE Test\",rmse_test1),  (\"r2_score Test\",r_squared_test1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "removed_split_model_train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_split_model_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_y1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_y1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos.PRICE.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Training - Actual Vs Predicted')\n",
    "plt.scatter(train_y1, train_pred_y1, c= \"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Test - Actual Vs Predicted')\n",
    "plt.scatter(test_y1, test_pred_y1, c= \"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Price')\n",
    "plt.ylabel('Predicted Price Residuals')\n",
    "plt.title('Training - Residuals Plot')\n",
    "plt.scatter(train_y1,train_y1 - train_pred_y1, c= \"green\")\n",
    "plt.hlines(y=0,xmin=0,xmax=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Price')\n",
    "plt.ylabel('Predicted Price Residuals')\n",
    "plt.title('Test - Residuals Plot')\n",
    "plt.scatter(test_y1, test_y1 - test_pred_y1, c= \"blue\")\n",
    "plt.hlines(y=0,xmin=0,xmax=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the parameters of each model to choose one to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline Model Metrics\") \n",
    "print(\"-\"*60)\n",
    "print(baseline_model_metrics)\n",
    "print()\n",
    "\n",
    "print(\"All Features Split Model Metrics\") \n",
    "print(\"-\"*60)\n",
    "print(\"Train: \", split_model_train_metrics)\n",
    "print(\"Test: \", split_model_test_metrics)\n",
    "print()\n",
    "\n",
    "print(\"Removed Features Split Model Metrics\") \n",
    "print(\"-\"*60)\n",
    "print(\"Train: \", removed_split_model_train_metrics)\n",
    "print(\"Test: \", removed_split_model_test_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The Baseline Model will perform w.r.t all performance metrics because, it uses more data to predict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comparing the performance metrics, the model consisting of all features is the better model and can be used for predicting__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Details:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model also performs close to the baseline model\n",
    "X = bos.drop('PRICE', axis = 1)\n",
    "Y = bos['PRICE']\n",
    "train_x,test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2,  random_state =100)\n",
    "lm = LinearRegression(normalize=True)\n",
    "model = lm.fit(train_x.values, train_y.values)\n",
    "\n",
    "#Model Co-efficients:\n",
    "model.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "233px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
